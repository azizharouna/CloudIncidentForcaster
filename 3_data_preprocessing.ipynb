{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utilspro.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>incident_state</th>\n",
       "      <th>active</th>\n",
       "      <th>reassignment_count</th>\n",
       "      <th>reopen_count</th>\n",
       "      <th>sys_mod_count</th>\n",
       "      <th>made_sla</th>\n",
       "      <th>caller_id</th>\n",
       "      <th>opened_by</th>\n",
       "      <th>opened_at</th>\n",
       "      <th>...</th>\n",
       "      <th>u_priority_confirmation</th>\n",
       "      <th>notify</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>rfc</th>\n",
       "      <th>vendor</th>\n",
       "      <th>caused_by</th>\n",
       "      <th>closed_code</th>\n",
       "      <th>resolved_by</th>\n",
       "      <th>resolved_at</th>\n",
       "      <th>closed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INC0000045</td>\n",
       "      <td>New</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2403</td>\n",
       "      <td>Opened by  8</td>\n",
       "      <td>29/2/2016 01:16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>code 5</td>\n",
       "      <td>Resolved by 149</td>\n",
       "      <td>29/2/2016 11:29</td>\n",
       "      <td>5/3/2016 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INC0000045</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2403</td>\n",
       "      <td>Opened by  8</td>\n",
       "      <td>29/2/2016 01:16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>code 5</td>\n",
       "      <td>Resolved by 149</td>\n",
       "      <td>29/2/2016 11:29</td>\n",
       "      <td>5/3/2016 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC0000045</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2403</td>\n",
       "      <td>Opened by  8</td>\n",
       "      <td>29/2/2016 01:16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>code 5</td>\n",
       "      <td>Resolved by 149</td>\n",
       "      <td>29/2/2016 11:29</td>\n",
       "      <td>5/3/2016 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INC0000045</td>\n",
       "      <td>Closed</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2403</td>\n",
       "      <td>Opened by  8</td>\n",
       "      <td>29/2/2016 01:16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>code 5</td>\n",
       "      <td>Resolved by 149</td>\n",
       "      <td>29/2/2016 11:29</td>\n",
       "      <td>5/3/2016 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INC0000047</td>\n",
       "      <td>New</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Caller 2403</td>\n",
       "      <td>Opened by  397</td>\n",
       "      <td>29/2/2016 04:40</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Do Not Notify</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>code 5</td>\n",
       "      <td>Resolved by 81</td>\n",
       "      <td>1/3/2016 09:52</td>\n",
       "      <td>6/3/2016 10:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number incident_state  active  reassignment_count  reopen_count  \\\n",
       "0  INC0000045            New    True                   0             0   \n",
       "1  INC0000045       Resolved    True                   0             0   \n",
       "2  INC0000045       Resolved    True                   0             0   \n",
       "3  INC0000045         Closed   False                   0             0   \n",
       "4  INC0000047            New    True                   0             0   \n",
       "\n",
       "   sys_mod_count  made_sla    caller_id       opened_by        opened_at  ...  \\\n",
       "0              0      True  Caller 2403    Opened by  8  29/2/2016 01:16  ...   \n",
       "1              2      True  Caller 2403    Opened by  8  29/2/2016 01:16  ...   \n",
       "2              3      True  Caller 2403    Opened by  8  29/2/2016 01:16  ...   \n",
       "3              4      True  Caller 2403    Opened by  8  29/2/2016 01:16  ...   \n",
       "4              0      True  Caller 2403  Opened by  397  29/2/2016 04:40  ...   \n",
       "\n",
       "  u_priority_confirmation         notify problem_id rfc vendor caused_by  \\\n",
       "0                   False  Do Not Notify          ?   ?      ?         ?   \n",
       "1                   False  Do Not Notify          ?   ?      ?         ?   \n",
       "2                   False  Do Not Notify          ?   ?      ?         ?   \n",
       "3                   False  Do Not Notify          ?   ?      ?         ?   \n",
       "4                   False  Do Not Notify          ?   ?      ?         ?   \n",
       "\n",
       "  closed_code      resolved_by      resolved_at       closed_at  \n",
       "0      code 5  Resolved by 149  29/2/2016 11:29  5/3/2016 12:00  \n",
       "1      code 5  Resolved by 149  29/2/2016 11:29  5/3/2016 12:00  \n",
       "2      code 5  Resolved by 149  29/2/2016 11:29  5/3/2016 12:00  \n",
       "3      code 5  Resolved by 149  29/2/2016 11:29  5/3/2016 12:00  \n",
       "4      code 5   Resolved by 81   1/3/2016 09:52  6/3/2016 10:00  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Displaying the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Steps:\n",
    "- Handle placeholder values (?).\n",
    "- Convert date columns to the proper datetime format.\n",
    "- Address the inconsistency with incidents marked as active but having a closed_at date.\n",
    "- Handle any other anomalies and inconsistencies identified during the EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling placeholder values (?)\n",
    "We previously identified several columns containing the placeholder value ?. We'll replace these placeholders with appropriate NaN (null) values, which will allow us to handle them more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caller_id               29\n",
       "opened_by             4835\n",
       "sys_created_by       53076\n",
       "sys_created_at       53076\n",
       "location                76\n",
       "category                78\n",
       "subcategory            111\n",
       "u_symptom            32964\n",
       "cmdb_ci             141267\n",
       "assignment_group     14213\n",
       "assigned_to          27496\n",
       "problem_id          139417\n",
       "rfc                 140721\n",
       "vendor              141468\n",
       "caused_by           141689\n",
       "closed_code            714\n",
       "resolved_by            226\n",
       "resolved_at           3141\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing '?' with NaN\n",
    "data.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Checking the number of missing values in each column after replacement\n",
    "missing_values = data.isna().sum()\n",
    "\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Based imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the KNN imputer may generate new labels not seen during the initial label encoding, we need to ensure that, post-imputation, only the known labels are used for inverse transformation.\n",
    "\n",
    "strategy:\n",
    "\n",
    "Using the KNN imputer on the data as before.\n",
    "Post-imputation, for the columns that were label-encoded, clip any values that lie outside the range [0, number of classes for that column - 1].\n",
    "Use inverse transformation on these clipped values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_cleaned_updated=missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns before imputation:  36\n",
      "Number of columns after imputation:  18\n",
      "Number of columns after replacement 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "number                     0\n",
       "incident_state             0\n",
       "active                     0\n",
       "reassignment_count         0\n",
       "reopen_count               0\n",
       "sys_mod_count              0\n",
       "made_sla                   0\n",
       "caller_id                  0\n",
       "opened_by                  0\n",
       "opened_at                  0\n",
       "sys_created_by             0\n",
       "sys_created_at             0\n",
       "sys_updated_by             0\n",
       "sys_updated_at             0\n",
       "contact_type               0\n",
       "location                   0\n",
       "category                   0\n",
       "subcategory                0\n",
       "u_symptom                  0\n",
       "cmdb_ci                    0\n",
       "impact                     0\n",
       "urgency                    0\n",
       "priority                   0\n",
       "assignment_group           0\n",
       "assigned_to                0\n",
       "knowledge                  0\n",
       "u_priority_confirmation    0\n",
       "notify                     0\n",
       "problem_id                 0\n",
       "rfc                        0\n",
       "vendor                     0\n",
       "caused_by                  0\n",
       "closed_code                0\n",
       "resolved_by                0\n",
       "resolved_at                0\n",
       "closed_at                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Selecting columns with missing values\n",
    "columns_with_missing = missing_values_cleaned_updated.index.tolist()\n",
    "\n",
    "# Creating a subset of data with these columns\n",
    "data_missing = data.copy()[columns_with_missing]\n",
    "\n",
    "# Label Encoding for categorical variables\n",
    "label_encoders = {}\n",
    "for col in columns_with_missing:\n",
    "    if data_missing[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        data_missing[col] = le.fit_transform(data_missing[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Scaling the data for KNN\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_missing)\n",
    "\n",
    "# Scaling the data for KNN\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_missing)\n",
    "\n",
    "# KNN Imputer initialization and imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "data_imputed = knn_imputer.fit_transform(data_scaled)\n",
    "\n",
    "# Convert imputed data back to dataframe\n",
    "data_imputed_df = pd.DataFrame(data_imputed, columns=columns_with_missing)\n",
    "\n",
    "# Clipping values for label encoded columns to ensure they lie within the known labels range\n",
    "for col, le in label_encoders.items():\n",
    "    max_label = len(le.classes_) - 1\n",
    "    data_imputed_df[col] = data_imputed_df[col].clip(0, max_label).astype(int)\n",
    "\n",
    "    # Inverse transform for label encoded columns\n",
    "    data_imputed_df[col] = le.inverse_transform(data_imputed_df[col])\n",
    "\n",
    "# Checking if missing values are imputed and if any unknown labels were introduced\n",
    "missing_after_imputation = data_imputed_df.isna().sum()\n",
    "\n",
    "missing_after_imputation\n",
    "#check the number of columns before and after imputation\n",
    "print('Number of columns before imputation: ', data.shape[1])\n",
    "print('Number of columns after imputation: ', data_imputed_df.shape[1])\n",
    "\n",
    "# Replacing the columns in the original dataset with the imputed versions\n",
    "data_cleaning = data.copy()\n",
    "for col in columns_with_missing:\n",
    "    data_cleaning[col] = data_imputed_df[col]\n",
    "\n",
    "# Checking the number of columns after the replacement\n",
    "num_columns_after_replacement = data_cleaning.shape[1]\n",
    "\n",
    "print('Number of columns after replacement', num_columns_after_replacement)\n",
    "\n",
    "data_cleaning.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'incident_state', 'active', 'reassignment_count',\n",
       "       'reopen_count', 'sys_mod_count', 'made_sla', 'caller_id', 'opened_by',\n",
       "       'opened_at', 'sys_created_by', 'sys_created_at', 'sys_updated_by',\n",
       "       'sys_updated_at', 'contact_type', 'location', 'category', 'subcategory',\n",
       "       'u_symptom', 'cmdb_ci', 'impact', 'urgency', 'priority',\n",
       "       'assignment_group', 'assigned_to', 'knowledge',\n",
       "       'u_priority_confirmation', 'notify', 'problem_id', 'rfc', 'vendor',\n",
       "       'caused_by', 'closed_code', 'resolved_by', 'resolved_at', 'closed_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaning.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opened_at         datetime64[ns]\n",
       "sys_created_at    datetime64[ns]\n",
       "resolved_at       datetime64[ns]\n",
       "closed_at         datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting date columns to datetime format\n",
    "date_columns = ['opened_at', 'sys_created_at', 'resolved_at', 'closed_at']\n",
    "for column in date_columns:\n",
    "    data_cleaning[column] = data_cleaning[column].apply(robust_date_parser)\n",
    "\n",
    "# Checking the datatypes of the columns after conversion\n",
    "data_cleaning[date_columns].dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's address the anomalies and inconsistencies we identified during our exploratory data analysis (EDA):\n",
    "\n",
    "- Incidents with closed_at dates but marked as active: \n",
    "We found 116,726 such incidents. This is inconsistent since active incidents should not have a closure date.\n",
    "- Potential Outliers:\n",
    "Reassignment Count: Some incidents have been reassigned more than 20 times.\n",
    "- Reopen Count: \n",
    "Some incidents have been reopened multiple times.\n",
    "- Sys Mod Count: \n",
    "Some incidents have more than 40 system modifications.\n",
    "\n",
    "### Addressing Anomalies:\n",
    "- Incidents with closed_at dates but marked as active:\n",
    "### Our solution: Set these incidents as inactive (active = False).\n",
    "\n",
    "- Potential Outliers:\n",
    "For each of the columns (Reassignment Count, Reopen Count, Sys Mod Count), we can:\n",
    "a. Cap the values at a certain threshold based on domain knowledge or statistical measures (like the 95th percentile).\n",
    "b. Investigate further to understand the reasons for such high values.\n",
    "c. Leave them as they are if they represent genuine scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting incidents with 'closed_at' dates but marked as 'active' to inactive\n",
    "data_cleaning.loc[(data_cleaning['active'] == True) & (data_cleaning['closed_at'].notna()), 'active'] = False\n",
    "\n",
    "# Checking the number of incidents that are still marked as 'active' but have a 'closed_at' date\n",
    "active_with_closed_date = data_cleaning[(data_cleaning['active'] == True) & (data_cleaning['closed_at'].notna())].shape[0]\n",
    "\n",
    "active_with_closed_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Outliers:\n",
    "\n",
    "For columns : Reassignment Count, Reopen Count, and Sys Mod Count, we can cap values beyond a threshold as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['reassignment_count', 'reopen_count', 'sys_mod_count']\n",
    "for column in columns_list:\n",
    "    threshold = data_cleaning[column].quantile(0.95)\n",
    "    data_cleaning[column] = data_cleaning[column].apply(lambda x: threshold if x > threshold else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "- Date Features: Extract relevant information from date columns.\n",
    "Day of the week, hour, and month from the opened_at column.\n",
    "Time taken to resolve an incident (difference between closed_at and opened_at).\n",
    "\n",
    "- Categorical Features: Convert categorical variables into a format suitable for machine learning models.\n",
    "One-hot encode categorical columns like incident_state, contact_type, and priority.\n",
    "For high cardinality categorical columns, consider using target encoding or other encoding techniques.\n",
    "\n",
    "- Text Features: If there are textual descriptions or notes in the dataset, derive features from them.\n",
    "Text length, sentiment analysis, or even more advanced techniques like TF-IDF or embeddings (this would depend on the nature and quality of the text data).\n",
    "\n",
    "- Interaction Features: Create interaction terms between relevant features, which can sometimes capture patterns that individual features might miss.\n",
    "\n",
    "- Normalization: Depending on the model we decide to use later, we might need to normalize or standardize some numerical features.\n",
    "\n",
    "Let's start by extracting features from the date columns, specifically from the opened_at column. We'll derive the day of the week, hour, and month from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opened_at</th>\n",
       "      <th>opened_day_of_week</th>\n",
       "      <th>opened_hour</th>\n",
       "      <th>opened_month</th>\n",
       "      <th>resolution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-29 04:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>149.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            opened_at  opened_day_of_week  opened_hour  opened_month  \\\n",
       "0 2016-02-29 01:16:00                   0            1             2   \n",
       "1 2016-02-29 01:16:00                   0            1             2   \n",
       "2 2016-02-29 01:16:00                   0            1             2   \n",
       "3 2016-02-29 01:16:00                   0            1             2   \n",
       "4 2016-02-29 04:40:00                   0            4             2   \n",
       "\n",
       "   resolution_time  \n",
       "0       130.733333  \n",
       "1       130.733333  \n",
       "2       130.733333  \n",
       "3       130.733333  \n",
       "4       149.333333  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting features from the 'opened_at' column\n",
    "data_cleaning['opened_day_of_week'] = data_cleaning['opened_at'].dt.dayofweek\n",
    "data_cleaning['opened_hour'] = data_cleaning['opened_at'].dt.hour\n",
    "data_cleaning['opened_month'] = data_cleaning['opened_at'].dt.month\n",
    "\n",
    "# Calculating the resolution time in hours (if it hasn't been calculated already)\n",
    "if 'resolution_time' not in data_cleaning.columns:\n",
    "    data_cleaning['resolution_time'] = (data_cleaning['closed_at'] - data_cleaning['opened_at']).dt.total_seconds() / (60 * 60)\n",
    "\n",
    "# Displaying the first few rows with the new features\n",
    "data_cleaning[['opened_at', 'opened_day_of_week', 'opened_hour', 'opened_month', 'resolution_time']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opened_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>resolution_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>130.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>130.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>130.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-29 01:16:00</td>\n",
       "      <td>2016-03-05 12:00:00</td>\n",
       "      <td>130.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-29 04:40:00</td>\n",
       "      <td>2016-03-06 10:00:00</td>\n",
       "      <td>149.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            opened_at           closed_at  resolution_duration\n",
       "0 2016-02-29 01:16:00 2016-03-05 12:00:00           130.733333\n",
       "1 2016-02-29 01:16:00 2016-03-05 12:00:00           130.733333\n",
       "2 2016-02-29 01:16:00 2016-03-05 12:00:00           130.733333\n",
       "3 2016-02-29 01:16:00 2016-03-05 12:00:00           130.733333\n",
       "4 2016-02-29 04:40:00 2016-03-06 10:00:00           149.333333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the resolution duration in hours\n",
    "data_cleaning['resolution_duration'] = (data_cleaning['closed_at'] - data_cleaning['opened_at']).dt.total_seconds() / 3600\n",
    "\n",
    "# Displaying the first few rows with the 'resolution_duration' feature\n",
    "data_cleaning[['opened_at', 'closed_at', 'resolution_duration']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 24918\n",
      "\n",
      "\n",
      "sys_updated_by 846\n",
      "\n",
      "\n",
      "sys_updated_at 50664\n",
      "\n",
      "\n",
      "cmdb_ci 30\n",
      "\n",
      "\n",
      "problem_id 14\n",
      "\n",
      "\n",
      "rfc 20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the high cardinality categorigal column\n",
    "categorical_columns = data_cleaning.select_dtypes(include=['object']).columns.tolist()\n",
    "high_cardinality_categorical_columns = []\n",
    "for column in categorical_columns:\n",
    "    #check the high cardinality categorigal column\n",
    "    if data_cleaning[column].nunique() > 10:\n",
    "        high_cardinality_categorical_columns.append(column)\n",
    "        print(column, data_cleaning[column].nunique())\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['number', 'sys_updated_by', 'sys_updated_at', 'cmdb_ci', 'problem_id', 'rfc']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cardinality_categorical_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
