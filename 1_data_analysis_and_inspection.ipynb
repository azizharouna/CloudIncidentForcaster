{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"utilspro.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set truncation threshold to display all rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Loading the dataset\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Displaying the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diplay the info of the dataset and the number of rows and columns and the nulls per columns in same functio\n",
    "# Extracting modes\n",
    "modes = data.mode()\n",
    "\n",
    "# Helper function to get the three most common\n",
    "def three_most_common(lst):\n",
    "    count = Counter(lst)\n",
    "    most_common = count.most_common(3)\n",
    "    return [item[0] for item in most_common]\n",
    "\n",
    "\n",
    "\n",
    "# Creating an information DataFrame\n",
    "info_df = pd.DataFrame({\n",
    "    'Column': data.columns,\n",
    "    'Dtype': data.dtypes.values,\n",
    "    'Null Count': data.isnull().sum().values,\n",
    "    'Non-Null Count': data.count().values,\n",
    "    'Unique Count': data.nunique().values,\n",
    "    '% Missing': (data.isnull().sum() / len(data) * 100).values,\n",
    "    '1st Mode': [three_most_common(data[col])[0] if len(three_most_common(data[col])) > 0 else None for col in data.columns],\n",
    "    '2nd Mode': [three_most_common(data[col])[1] if len(three_most_common(data[col])) > 1 else None for col in data.columns],\n",
    "    '3rd Mode': [three_most_common(data[col])[2] if len(three_most_common(data[col])) > 2 else None for col in data.columns],\n",
    "    'Skewness': data.skew().values,\n",
    "    'Kurtosis': data.kurt().values,\n",
    "})\n",
    "\n",
    "info_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comments:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data structure (data types and missing values)\n",
    "data_info = data.info()\n",
    "\n",
    "# Checking for placeholder values (assuming '?' is a placeholder)\n",
    "placeholder_counts = data.apply(lambda x: x[x == '?'].count())\n",
    "\n",
    "# Getting statistical summary of the dataset for numerical columns\n",
    "data_summary = data.describe()\n",
    "\n",
    "data_info, placeholder_counts, data_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Data Columns and Types:\n",
    "The dataset has 141,712 entries and 36 columns.\n",
    "Data types include objects (strings), integers, and booleans.\n",
    "Several columns like opened_at, resolved_at, and closed_at are of object type (strings) representing dates. We may need to convert these to datetime format for further analysis.\n",
    "\n",
    "* #### Placeholder Values (?):\n",
    "Several columns contain the placeholder value ?. For instance, the cmdb_ci column has 141,267 such values, which is a significant portion of the total entries.\n",
    "Other columns with a high count of placeholders include sys_created_by, u_symptom, problem_id, rfc, vendor, and caused_by.\n",
    "\n",
    "* ### Statistical Summary:\n",
    "reassignment_count ranges from 0 to 27, with an average of around 1.1.\n",
    "reopen_count has a maximum value of 8, but 75% of the data is still 0, indicating that most incidents are not reopened.\n",
    "sys_mod_count (probably indicating system modifications) has a wide range, with values from 0 to 129 and an average of around 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Granularity and uniqueness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the uniqueness of the 'number' column\n",
    "unique_incidents = data['number'].nunique()\n",
    "total_entries = len(data)\n",
    "\n",
    "unique_incidents, total_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 24,918 unique incidents (as indicated by the number column).\n",
    "* 141,712 total entries.\n",
    "\n",
    "This suggests that the dataset is not at the granularity of individual incidents. Instead, each incident has multiple entries, possibly capturing different states or updates related to the incident over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution\n",
    "\n",
    "We'll focus on the following columns:\n",
    "\n",
    " * Numerical: reassignment_count, reopen_count, and sys_mod_count.\n",
    "* Categorical: incident_state, contact_type, and priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the plotting environment\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plotting the distribution of the numerical columns\n",
    "numerical_columns = ['reassignment_count', 'reopen_count', 'sys_mod_count']\n",
    "\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(data[column], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Reassignment Count:\n",
    " Most incidents are reassigned once or not at all, with a sharp decline in frequency as the number of reassignments increases.\n",
    "* ### Reopen Count:\n",
    "The vast majority of incidents are not reopened. Only a small number of incidents have been reopened multiple times.\n",
    "* ### Sys Mod Count (System Modification Count):\n",
    " Most incidents have a system modification count between 0 and 10. However, there's a long tail, indicating that some incidents have been modified many time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " let's visualize the distribution of the selected categorical columns: incident_state, contact_type, and priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of the categorical columns\n",
    "categorical_columns = ['incident_state', 'contact_type', 'priority']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, column in enumerate(categorical_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(data=data, y=column, order=data[column].value_counts().index)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Incident State:\n",
    "The most common state is \"Active\", followed by \"New\" and \"Resolved\".\n",
    "States like \"Awaiting Problem\", \"Awaiting Vendor\", and \"Awaiting Evidence\" have considerably fewer occurrences.\n",
    "* ### Contact Type:\n",
    "The vast majority of incidents are reported via \"Phone\", with very few incidents reported through \"Email\", \"Self service\", or \"Direct opening\".\n",
    "* ### Priority:\n",
    "The \"3 - Moderate\" priority level is the most common, followed by \"2 - High\" and \"4 - Low\". There are fewer incidents with \"1 - Critical\" and \"5 - Very Low\" priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical columns\n",
    "correlation_matrix = data[numerical_columns].corr()\n",
    "\n",
    "# Plotting the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Reassignment Count and Sys Mod Count: \n",
    "There's a light positive correlation (approximately 0.53) between these two variables. This indicates that as incidents are reassigned more often, the number of system modifications also tends to increase.\n",
    "* ### Reopen Count:\n",
    "This variable doesn't have a strong correlation with the other two. Its correlation with both reassignment_count and sys_mod_count is relatively low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection\n",
    "\n",
    "We'll focus on identifying potential outliers within the numerical columns. Outliers can distort the results of our analyses and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting boxplots for anomaly detection in numerical columns\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(data[column])\n",
    "    plt.title(f'Box Plot of {column}')\n",
    "    plt.xlabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Reassignment Count:\n",
    "Most of the data points lie between 0 and 2. However, there are several outliers beyond this range, with some incidents having been reassigned more than 20 times.\n",
    "* #### Reopen Count:\n",
    "While the majority of incidents are not reopened, there are outliers where incidents have been reopened multiple times.\n",
    "* #### Sys Mod Count:\n",
    "Most of the incidents have undergone system modifications less than 15 times. Yet, there are outliers, with some incidents having more than 40 system modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Consistency \n",
    "we'll focus on checking if:\n",
    "* There are incidents with a closed_at date earlier than the opened_at date.\n",
    "* Identifying any incidents that are marked as active but have a closed_at date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'opened_at', 'closed_at' to datetime format\n",
    "data['opened_at'] = pd.to_datetime(data['opened_at'], errors='coerce', dayfirst=True)\n",
    "data['closed_at'] = pd.to_datetime(data['closed_at'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Checking for incidents with 'closed_at' date earlier than 'opened_at' date\n",
    "inconsistent_dates = data[data['closed_at'] < data['opened_at']]\n",
    "\n",
    "# Checking for incidents that are marked as 'active' but have a 'closed_at' date\n",
    "active_but_closed = data[(data['active'] == True) & (~data['closed_at'].isna())]\n",
    "\n",
    "inconsistent_dates_count = len(inconsistent_dates)\n",
    "active_but_closed_count = len(active_but_closed)\n",
    "\n",
    "inconsistent_dates_count, active_but_closed_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### There are no incidents with a closed_at date earlier than the opened_at date.\n",
    " This is good as it indicates consistent date information.\n",
    "* #### There are 116,726 incidents that are marked as active but have a closed_at date.\n",
    " This is peculiar and suggests potential inconsistencies in the data. Incidents that are still active shouldn't have a closure date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB :  It's crucial to address identified inconsistencies and anomalies before proceeding with  building machine learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
